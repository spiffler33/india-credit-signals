# WHY THIS: Single source of truth for all training data format parameters.
# Changing split dates, held-out entities, or vocabulary means editing this YAML —
# not hunting through Python code. Reproducible experiments need diffable configs.

# --- Instruction (fixed across all training examples) ---
# "Financial institution" not "NBFC" because ~11% of corpus is banks (YES Bank,
# LVB, PMC Bank) or infra finance (IL&FS). Saying "NBFC" would be factually
# wrong for those articles and could bias the model's framing.
instruction: >-
  Assess whether this news article contains signals relevant to the credit
  quality of the mentioned Indian financial institution.

# --- Text Handling ---
text:
  max_chars: 3000  # Matches labeling pipeline truncation from Phase 1.3

# --- Temporal Split ---
# Strict date-based to prevent data leakage. Train on crisis era, validate on
# quiet period, test on forward period (simulates production deployment).
splits:
  train_end: "2021-12-31"        # Train: 2017-04 to 2021-12 (crisis + recovery)
  val_end: "2023-06-30"          # Val: 2022-01 to 2023-06 (quiet period, tune hyperparams)
  # Test: 2023-07 to 2024-12    # Everything after val_end

# --- Entity Holdout Diagnostic ---
# These entities are removed entirely from training (single-entity articles only)
# to test whether the model learned text patterns or just memorized entity names.
# Multi-entity articles mentioning held-out entities stay in the main split.
entity_holdout:
  - "DHFL"                  # Crisis (91% deterioration) — distress detection test
  - "Reliance Capital"      # Crisis (80% deterioration) — generalization test
  - "Cholamandalam"         # Stable (22% CR) — false positive control

# --- Strict Output Vocabulary ---
# Parser rejects any value not in these lists. This catches model drift early.
vocabulary:
  credit_relevant:
    - "Yes"
    - "No"
  direction:
    - "Deterioration"
    - "Improvement"
    - "Neutral"
  signal_type:
    - "liquidity"
    - "asset_quality"
    - "regulatory"
    - "contagion"
    - "governance"
    - "funding"
    - "operational"
    - "other"
  sector_wide:
    - "Yes"
    - "No"
  confidence:
    - "Low"
    - "Medium"
    - "High"

# --- Input Data Paths ---
paths:
  labels: "data/processed/labels_final.jsonl"
  articles: "data/processed/gdelt_for_labeling.csv"
  output_dir: "data/processed"

# --- Output Field Mapping ---
# Maps internal label values to training output text. Keeps the mapping
# in config so the Python code has no hardcoded domain knowledge.
direction_map:
  -1: "Deterioration"
  0: "Neutral"
  1: "Improvement"

confidence_map:
  "low": "Low"
  "medium": "Medium"
  "high": "High"
